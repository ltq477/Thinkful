{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 34071,
     "status": "ok",
     "timestamp": 1604372211031,
     "user": {
      "displayName": "Lawrence Quesada",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgDfi5ZMUHec5oABIqu-Gh8jDLncpZUMsEadkSem7Y=s64",
      "userId": "14131790862529985455"
     },
     "user_tz": 480
    },
    "id": "wYvNv-Uj-ULh",
    "outputId": "7c353ce7-4530-40f6-e32d-e1e5b3e38ac7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZANtNG8O9yku"
   },
   "source": [
    "# Introduction\n",
    "\n",
    "In this project, we will attempt to greate a Generative Adversarial Network (GAN) in order to manipulate facial expressions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JQq79p3Q9ykw"
   },
   "source": [
    "Our first step is to load the neccessary libraries we will be using for the entire process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 5452,
     "status": "ok",
     "timestamp": 1604372239146,
     "user": {
      "displayName": "Lawrence Quesada",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgDfi5ZMUHec5oABIqu-Gh8jDLncpZUMsEadkSem7Y=s64",
      "userId": "14131790862529985455"
     },
     "user_tz": 480
    },
    "id": "ay4pmFE69ykx"
   },
   "outputs": [],
   "source": [
    "#Loading the neccessary libraries\n",
    "from __future__ import print_function\n",
    "%matplotlib inline\n",
    "from IPython.display import HTML\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import argparse\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transform\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import datasets, transforms, utils\n",
    "\n",
    "from skimage import io\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.animation as animation\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 6984,
     "status": "aborted",
     "timestamp": 1604371865116,
     "user": {
      "displayName": "Lawrence Quesada",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgDfi5ZMUHec5oABIqu-Gh8jDLncpZUMsEadkSem7Y=s64",
      "userId": "14131790862529985455"
     },
     "user_tz": 480
    },
    "id": "4itUB_-B9ym0"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-410d78ed2b3c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mdataroot\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"/Data/AnimeFaces/\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m dataset = dset.ImageFolder(root=dataroot,\n\u001b[0m\u001b[0;32m      3\u001b[0m                            transform=transforms.Compose([\n\u001b[0;32m      4\u001b[0m                                \u001b[0mtransforms\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mResize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m                                \u001b[0mtransforms\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCenterCrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'dset' is not defined"
     ]
    }
   ],
   "source": [
    "dataroot = \"/Data/AnimeFaces/\"\n",
    "dataset = dset.ImageFolder(root=dataroot,\n",
    "                           transform=transforms.Compose([\n",
    "                               transforms.Resize(image_size),\n",
    "                               transforms.CenterCrop(image_size),\n",
    "                               transforms.ToTensor(),\n",
    "                               transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "                           ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "Facial Gans and Facial Expressions ver_II - colab.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
