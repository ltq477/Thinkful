{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like Pandas dataframes, NumPy arrays can only work in memory. The good news is that Dask also supports NumPy arrays in a similar way to it does Pandas. It provides a structure called `Array` which enhances NumPy arrays with parallelization capabilities. In a nutshell, A Dask array coordinates several NumPy arrays as the figure below demonstrates:\n",
    "\n",
    "![Dask array](dask_array.svg)\n",
    "\n",
    "Moreover, Dask arrays provide most of the familiar NumPy functionalities and apis and hence using them in our code is something like writing code using NumPy. This is the beauty of Dask."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working with Dask arrays\n",
    "\n",
    "There are basically three advantages of using Dask arrays instead of NumPy arrays:\n",
    "\n",
    "*  **Parallel**: Dask can use all of the cores on the computer it runs on. Even more, it can scale to multiple machines.\n",
    "\n",
    "*   **Larger-than-memory**: NumPy arrays can only work with data that fits into the memory. Dask arrays let us work on datasets that are larger than the available memory by breaking up the arrays into many smaller pieces called **chunks**. This is illustrated in the figure below:\n",
    "\n",
    "<img src=\"array.png\" width=\"25%\">\n",
    "\n",
    "*  **Blocked Algorithms**: Blocked algorithms are the algorithms that perform a large computation by dividing it into smaller computations and then aggregating the results. Hence, when implementing a blocked algorithm using Dask arrays instead of NumPy arrays, we can take advantage of the parallelization. \n",
    "\n",
    "We'll start using Dask arrays with generating random values. But before that, we start a Dask client. Remember that starting a client isn't necessary when working with Dask on our local computer but still it provides us a dashboard where we can investigate our computations. We'll again configure our client to have as four workers and 2 thread in each worker. We also set 2GB memory limit to each worker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"border: 2px solid white;\">\n",
       "<tr>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Client</h3>\n",
       "<ul style=\"text-align: left; list-style: none; margin: 0; padding: 0;\">\n",
       "  <li><b>Scheduler: </b>tcp://127.0.0.1:50485</li>\n",
       "  <li><b>Dashboard: </b><a href='http://127.0.0.1:50486/status' target='_blank'>http://127.0.0.1:50486/status</a>\n",
       "</ul>\n",
       "</td>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Cluster</h3>\n",
       "<ul style=\"text-align: left; list-style:none; margin: 0; padding: 0;\">\n",
       "  <li><b>Workers: </b>4</li>\n",
       "  <li><b>Cores: </b>8</li>\n",
       "  <li><b>Memory: </b>8.00 GB</li>\n",
       "</ul>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Client: 'tcp://127.0.0.1:50485' processes=4 threads=8, memory=8.00 GB>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from dask.distributed import Client, progress\n",
    "\n",
    "client = Client(n_workers=4, threads_per_worker=2, memory_limit='2GB')\n",
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Dask as if it's NumPy\n",
    "\n",
    "We'll be using Dask arrays by creating random arrays and do mathematical calculations on them. We also do the same thing using NumPy arrays and compare the run times.\n",
    "\n",
    "## Creating a random array\n",
    "\n",
    "In order to use Dask arrays, we need to import it as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.array as da\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we create a 10000x10000 array of random numbers. Note that we set `chunks` parameter to `(1000, 1000)`. This is something different than what we normally do when generating random arrays with NumPy. By setting chunks, we tell Dask that it should represent as many numpy arrays of size 1000x1000 (or smaller if the array cannot be divided evenly). In our case, there will be 100 numpy arrays of size 1000x1000.\n",
    "\n",
    "What we do below is:\n",
    "\n",
    "* We first create a random Dask array of size 10000X10000.\n",
    "* Then we add this array to its transpose.\n",
    "* Last, we filter the resulting array and calculate its mean.\n",
    "\n",
    "As usual, we call `.compute()` to make Dask evaluate the results. Note that we calculate the run time of the following cell using jupyter notebook's magic command `%%time`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 386 ms, sys: 40.6 ms, total: 427 ms\n",
      "Wall time: 1.51 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "x = da.random.random((10000, 10000), chunks=(1000, 1000))\n",
    "y = x + x.T\n",
    "z = y[::2, 5000:].mean(axis=1)\n",
    "z.compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, notice that the code above is almost identical to what we would write by using NumPy. The only difference is that we set the `chunks` parameter to when generating a random Dask array.\n",
    "\n",
    "Second, our code block took 427 milliseconds to run."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's do the same thing using NumPy arrays:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.89 s, sys: 873 ms, total: 3.76 s\n",
      "Wall time: 3.97 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "x = np.random.random((10000, 10000))\n",
    "y = x + x.T\n",
    "z = y[::2, 5000:].mean(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we run the same code using NumPy, it took 3.76 seconds to run which is equivalent to 3760 milliseconds. That is, running the same operations took almost 9 times longer when using NumPy instead of Dask."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Persisting data in memory\n",
    "\n",
    "So far, we saw that we can use Dask arrays instead of NumPy arrays to parallelize the computations. Moreover, using Dask, we can even work with data that doesn't fit into the memory. However, If we have the available memory for an array and just want to speed up the computations using Dask, then we can persist the data in memory and take advantage of the memory speed. If we do this, all of the future computations on the persisted array will be much faster.\n",
    "\n",
    "We demonstrate this doing the same computations before and after we persist our Dask array into the memory. First, we make our computations without persisting the array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = da.random.random((10000, 10000), chunks=(1000, 1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 343 ms, sys: 132 ms, total: 475 ms\n",
      "Wall time: 1.08 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "y = x + x.T\n",
    "z = y[::2, 5000:].mean(axis=1)\n",
    "z.compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we do the same thing this time after persisting our array into the memory. In order to persist an array to memory, we just call `.persist()` method of the Dask arrays:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr>\n",
       "<td>\n",
       "<table>\n",
       "  <thead>\n",
       "    <tr><td> </td><th> Array </th><th> Chunk </th></tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr><th> Bytes </th><td> 800.00 MB </td> <td> 8.00 MB </td></tr>\n",
       "    <tr><th> Shape </th><td> (10000, 10000) </td> <td> (1000, 1000) </td></tr>\n",
       "    <tr><th> Count </th><td> 100 Tasks </td><td> 100 Chunks </td></tr>\n",
       "    <tr><th> Type </th><td> float64 </td><td> numpy.ndarray </td></tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</td>\n",
       "<td>\n",
       "<svg width=\"170\" height=\"170\" style=\"stroke:rgb(0,0,0);stroke-width:1\" >\n",
       "\n",
       "  <!-- Horizontal lines -->\n",
       "  <line x1=\"0\" y1=\"0\" x2=\"120\" y2=\"0\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"0\" y1=\"12\" x2=\"120\" y2=\"12\" />\n",
       "  <line x1=\"0\" y1=\"24\" x2=\"120\" y2=\"24\" />\n",
       "  <line x1=\"0\" y1=\"36\" x2=\"120\" y2=\"36\" />\n",
       "  <line x1=\"0\" y1=\"48\" x2=\"120\" y2=\"48\" />\n",
       "  <line x1=\"0\" y1=\"60\" x2=\"120\" y2=\"60\" />\n",
       "  <line x1=\"0\" y1=\"72\" x2=\"120\" y2=\"72\" />\n",
       "  <line x1=\"0\" y1=\"84\" x2=\"120\" y2=\"84\" />\n",
       "  <line x1=\"0\" y1=\"96\" x2=\"120\" y2=\"96\" />\n",
       "  <line x1=\"0\" y1=\"108\" x2=\"120\" y2=\"108\" />\n",
       "  <line x1=\"0\" y1=\"120\" x2=\"120\" y2=\"120\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Vertical lines -->\n",
       "  <line x1=\"0\" y1=\"0\" x2=\"0\" y2=\"120\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"12\" y1=\"0\" x2=\"12\" y2=\"120\" />\n",
       "  <line x1=\"24\" y1=\"0\" x2=\"24\" y2=\"120\" />\n",
       "  <line x1=\"36\" y1=\"0\" x2=\"36\" y2=\"120\" />\n",
       "  <line x1=\"48\" y1=\"0\" x2=\"48\" y2=\"120\" />\n",
       "  <line x1=\"60\" y1=\"0\" x2=\"60\" y2=\"120\" />\n",
       "  <line x1=\"72\" y1=\"0\" x2=\"72\" y2=\"120\" />\n",
       "  <line x1=\"84\" y1=\"0\" x2=\"84\" y2=\"120\" />\n",
       "  <line x1=\"96\" y1=\"0\" x2=\"96\" y2=\"120\" />\n",
       "  <line x1=\"108\" y1=\"0\" x2=\"108\" y2=\"120\" />\n",
       "  <line x1=\"120\" y1=\"0\" x2=\"120\" y2=\"120\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Colored Rectangle -->\n",
       "  <polygon points=\"0.000000,0.000000 120.000000,0.000000 120.000000,120.000000 0.000000,120.000000\" style=\"fill:#ECB172A0;stroke-width:0\"/>\n",
       "\n",
       "  <!-- Text -->\n",
       "  <text x=\"60.000000\" y=\"140.000000\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" >10000</text>\n",
       "  <text x=\"140.000000\" y=\"60.000000\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" transform=\"rotate(-90,140.000000,60.000000)\">10000</text>\n",
       "</svg>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "dask.array<random_sample, shape=(10000, 10000), dtype=float64, chunksize=(1000, 1000), chunktype=numpy.ndarray>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = da.random.random((10000, 10000), chunks=(1000, 1000))\n",
    "# This persists the x array into the memory\n",
    "x.persist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we run the same computations above after persisting the array into the memory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 236 ms, sys: 22.5 ms, total: 259 ms\n",
      "Wall time: 514 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "y = x + x.T\n",
    "z = y[::2, 5000:].mean(axis=1)\n",
    "z.compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we see, when we persisted the array into the memory and made the computations, it took around half the time of the computations when we didn't persist the array."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Drawbacks of Dask arrays\n",
    "\n",
    "As is the case for Dask dataframes, `Dask.array` package doesn't implement the entire NumPy interface. The main differences are the following:\n",
    "\n",
    "1. Dask project is an ongoing one and NumPy has a huge api. So, implementing them takes time.\n",
    "\n",
    "2. Some operations like sorting is difficult to parallelize as we discussed in the previous checkpoint. So, some functionalities around sorting is deliberately not supported in Dask.\n",
    "\n",
    "3. If the results of an operation depends on the values in the inputs, then Dask doesn't implement these operations. This is because of the lazy evaluation strategy of Dask.\n",
    "\n",
    "That being said, many of the most commonly used functionalities of NumPy are available in the Dask dataframes. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Closing the connection\n",
    "\n",
    "We're done with the Dask for this checkpoint. So, we can close our connection:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
