{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing the neccessary libraries for analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading the Data into the fashion_df Dataframe\n",
    "fashion_df = tf.keras.datasets.fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Splitting the Data using Test and training sets.\n",
    "(X_train, y_train), (X_test, y_test) = fashion_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(10000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "#Viewing the shape of the initial Dataframe split into Training and Testing sets\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EDA by initially plotting the data and viewing its contents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABH4AAAESCAYAAACLuxKfAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3de4xeZ3Uo/PV4Lr7GdkJiElKSEMItCZS0Lpc2AqJTLm1pQ4tOdPjjiFPBSUVB/VodlaKWXlTpk6A6ab5SWlRuIpXK5SBoQRTxcUlKSPhICLSQCwRDiInjWxInjscz9lze5/sjQxWCvde233dm9mz/flJke9bK2mv2zF7vnjXvvFNqrQEAAABA/6xZ6QYAAAAAWBoWPwAAAAA9ZfEDAAAA0FMWPwAAAAA9ZfEDAAAA0FMWPwAAAAA9Nb6cByul+N3xS+Tnf/7nG+MHDhxIa8zOzg7dx6OPPprmjI/nn3ZtcjIbNmxIc3bu3Dn0cU5RD9Zaz1rpJk6WWfTTtm7dmuacc845aU42a/bt29e6p9UiOy+nn356WuOBBx4YSc4pyCzimNasaf7e5lOf+tS0xqFDh9KchYWFoeIREbXmnwZt7mnWrl07dC979uxJczgmswjoguPOoqG+ui6lvCoi/iYixiLi/bXWdwxTj5N32223NcY/8pGPpDV+9KMfpTnZzcn111+f1mjzBeaZZ56Z5oyNjTXGL7vssrTGG97whjSHY+rUxswsGt4VV1yR5rz97W9Pcz760Y82xq+55pq0xmAwSHO65I1vfGNj/LWvfW1a4/3vf3+a8+53v7t1T6cQs4hjWr9+fWP8z//8z9MaX/jCF9Kc6enpxvjBgwfTGkeOHElz2tzTPPOZz2yMP/zww2mNv/zLv0xzOKZOzaII8whOUcedRSf9o16llLGI+LuI+JWIuDgiXldKufhk6wGcDLMI6AKzCOgK8wh4omFe4+cFEfH9Wus9tdbZiPhoRFw5mrYAWjOLgC4wi4CuMI+AnzDM4ufciLjvcf/etfg2gOVkFgFdYBYBXWEeAT9hmNf4Kcd420+9AEwp5eqIuHqI4wA0MYuALjCLgK5I55FZBKeWYRY/uyLi8b8S4WciYvcTk2qt742I90Z4xXhgSZhFQBeYRUBXpPPILIJTyzA/6vX1iHhGKeVppZTJiPhvEfHp0bQF0JpZBHSBWQR0hXkE/ISTfsZPrXW+lPKWiPh/47FfE/jBWuudI+sMoAWzCOgCswjoCvMIeKJS6/I9s8/TCE/O+eefn+a8733va4zff//9aY2pqamhe1lYWEhrzM/PpzkHDx5Mc2ZmZhrjd999d1rj3e9+d5rDMX2j1rp9pZs4WX2bRW9961vTnD/90z9tjLe5Lufm5tKcM844ozE+NjaW1mjji1/8YmP87/7u79Ia1157bZpzwQUXpDnZuTtw4EBaY+3atWnOli1bGuM33nhjWuOKK65IcwaDQZrTIWYRx/TKV76yMf65z31umTpZXUo51kvD0IJZBHTBcWfRMD/qBQAAAECHWfwAAAAA9JTFDwAAAEBPWfwAAAAA9JTFDwAAAEBPWfwAAAAA9JTFDwAAAEBPja90A+R++7d/O80577zzGuO7du1Ka2zYsCHNOXjwYGN8MBikNdr0sn79+jTny1/+cmP8jjvuSGuUUtKcWmuaA0vl+uuvT3Muv/zyNOfAgQON8cOHD6c12lwLWU6bOTM+nj80vfCFL2yMX3zxxWmNzZs3pzlTU1ND58zMzKQ12pz/Rx55pDGenZOIiH/7t39Lc17ykpekOdB1559//tA12lz/Y2NjQ8Uj2s286enpNCezadOmoWsAsDp5xg8AAABAT1n8AAAAAPSUxQ8AAABAT1n8AAAAAPSUxQ8AAABAT1n8AAAAAPSUxQ8AAABAT1n8AAAAAPTU+Eo3QO6mm25Kc84777zG+J133pnW2Lp1a5rzghe8oDF+3333pTU++clPpjm//uu/nua85CUvaYxPTk6mNfbv35/mHDp0KM2Bk/Urv/IrjfEXvehFaY177703zcmuh3Xr1qU1Zmdn05zp6enGeJs5c+TIkTRnYmKiMX7mmWemNdq8P23MzMw0xsfH84faUsrQfezcuTPNyWZ4RMSrX/3qxvhnPvOZ1j3BSjn//PMb47XWtEY2Z9pYWFhIc+bn59OcsbGxoXtp4/TTT09zHn744WXoBIBR8owfAAAAgJ6y+AEAAADoKYsfAAAAgJ6y+AEAAADoKYsfAAAAgJ6y+AEAAADoKYsfAAAAgJ6y+AEAAADoqfGVboDcWWedleZ873vfa4wfOnQorXH22WenOXfffXdj/ODBg2mNq6++Os05evRomnPrrbc2xqemptIac3NzaQ4spTe+8Y2N8fn5+bTGxMREmjM2NtYYX1hYSGuMj+cPGTMzM43xRx99NK2xdevWNOfIkSON8TbX9saNG9OcPXv2pDmllKHiERGDwSDNyUxOTqY5s7Ozac6b3vSmxvhnPvOZ1j3BSrn88ssb422uyzb3Itl11+Y4bXJqrWlOmzmeef7zn5/m3HDDDUMfB4Dl5Rk/AAAAAD1l8QMAAADQUxY/AAAAAD1l8QMAAADQUxY/AAAAAD1l8QMAAADQUxY/AAAAAD01vtINkHv2s5+d5px55pmN8dtvvz2t8dznPjfNmZ2dbYxfcMEFaY3LL788zfnYxz6W5px11lmN8UOHDqU1Lr300jTntttuS3PgZF100UWN8ZmZmbRGKSXNqbW27mmYGuvWrWuMP/LII2mNDRs2pDmTk5ON8fHx/OHtoYceSnOmp6fTnOx9HgwGaY1RfHzGxsbSnKmpqTTnOc95ztC9wEprc0+TWa7Z2uY4bXLazJrMJZdckubccMMNQx8HgOU11OKnlHJvRByKiIWImK+1bh9FUwAnyjwCusAsArrALAIebxTP+Lmi1vrgCOoADMs8ArrALAK6wCwCIsJr/AAAAAD01rCLnxoRny+lfKOUcvUoGgI4SeYR0AVmEdAFZhHwn4b9Ua9fqrXuLqVsi4gvlFK+W2u98fEJi4PGsAGWWuM8MouAZWIWAV1gFgH/aahn/NRady/+uT8i/jkiXnCMnPfWWrd7QTFgKWXzyCwCloNZBHSBWQQ83kkvfkopG0spp/347xHxioi4Y1SNAbRlHgFdYBYBXWAWAU80zI96PTki/rmU8uM6H661fm4kXQGcGPMI6AKzCOgCswj4CSe9+Km13hMRPzvCXjiOycnJNGdubq4xvm7durTGPffck+asWdP8JLHNmzenNb7yla+kOQcPHkxzbr311sb4zp070xpt+qX7ujqPXvrSl6Y555xzTmN8eno6rZFdlxER8/PzjfFa60iOk+W0qbFv37405/TTT2+MZzMxIuLhhx9OcyYmJtKcURjFx3BsbCytcfTo0TQnO7d/9Vd/ldZ461vfmub0UVdn0ako+zweDAZpjTbX1ChqLCwspDmjmtGZ7dv91E8fmEXAE/l17gAAAAA9ZfEDAAAA0FMWPwAAAAA9ZfEDAAAA0FMWPwAAAAA9ZfEDAAAA0FMWPwAAAAA9ZfEDAAAA0FPjK90AubvuuivNGR9v/lBOT0+PpJeNGzc2xi+55JK0xo4dO9Kcbdu2pTl/+Id/2Bh/4QtfmNZ47nOfm+bAydq+fXuas2nTpsb4xMREWqOUkuaMjY01xqemptIaMzMzaU6mzfuzsLCQ5jz88MON8VprWmPt2rVpTnbe2hgMBmlOm4/hGWecMfRx1qzJv99z6NChxvhnP/vZtAZ0XZvrpU3O+vXrh+6lzVycn59Pc44ePTp0L0960pOGrgFA93jGDwAAAEBPWfwAAAAA9JTFDwAAAEBPWfwAAAAA9JTFDwAAAEBPWfwAAAAA9JTFDwAAAEBPja90A+Smp6fTnN/7vd9rjN98881pjS996UtpzjOf+czG+H333ZfWWLMm3zcePHgwzXnooYca429961tHchw4Wddcc02a88UvfrEx/rnPfS6tcfbZZ6c5r3vd6xrj1113XVpj165daU4ppTFea01rtJkRy1EjImJ+fn5Zajz96U9Pc972trc1xt/+9renNdavX5/mZHN+//79aQ1YaTMzM43xNtdCViMiYtOmTY3xd73rXWmNX/iFX0hzXvziF6c5hw8fTnMyjz766NA1gOU3MTHRGJ+bm0trbN26Nc3ZsGFDmrOwsNAYf8YznpHWaHNvm93rbdu2La2RnbeI/Gvx7L4pIuJ5z3temvPNb36zMf5Hf/RHaY0mnvEDAAAA0FMWPwAAAAA9ZfEDAAAA0FMWPwAAAAA9ZfEDAAAA0FMWPwAAAAA9ZfEDAAAA0FMWPwAAAAA9Nb7SDZDbu3dvmvPc5z63Mb527dq0xoc//OE0Z+PGjY3xf/mXf0lr/O7v/m6a86//+q9pzg033NAYv/vuu9Mac3NzaQ4spW9961uN8XPOOWdZ+vjIRz6S5kxOTqY5CwsLjfFSSuuemtRaG+Pz8/NpjbGxsZHkDAaDxvj4eP5Q2+a8fPWrX22Mb968Oa0Bp4of/vCHjfGLL744rdFm5mW++93vpjlnnHFGmvPiF784zRnFPc0PfvCDoWsAy28U91fvfOc705yrr746zfnyl7/cGG9zb9vm/uvf//3fG+NtZuvBgwfTnEceeaQx/rM/+7NpjbPOOivNefazn90Y//u///u0xs6dO48b84wfAAAAgJ6y+AEAAADoKYsfAAAAgJ6y+AEAAADoKYsfAAAAgJ6y+AEAAADoKYsfAAAAgJ6y+AEAAADoqfEsoZTywYh4dUTsr7Veuvi2MyLiYxFxQUTcGxFX1VofXro2T2333XdfmvOxj32sMV5rTWuMj6efDjEzM9MY37t3b1rj6NGjac6znvWsoXvZunVrWuOBBx5IcxYWFtIcll5fZ1EppTHe5tpdLmvWLM/3CgaDQZqTnbfl6jUiYnJysjE+Pz8/kuNs3LhxJHUYXl/nUZ/s2LGjMX7xxRenNUYxf6+//vo0p00vbWSzqI3svNEtZtHSaXMfMTY2NvRxRvV1xuzsbGN8y5YtaY029yu/8Ru/kebMzc01xl/72temNdatW5fmvPnNb26Mn3baaWmN7OvJiIgDBw40xv/2b/82rXHVVVelObfeemtjfOfOnWmNJm3ujD8UEa96wtveFhFfqrU+IyK+tPhvgKX0oTCLgG74UJhHwMr7UJhFQAvp4qfWemNEPHHNdWVEXLf49+si4jUj7gvgJ5hFQFeYR0AXmEVAWyf7XPgn11r3REQs/rltdC0BtGYWAV1hHgFdYBYBPyV/UZchlVKujoirl/o4AE3MIqALzCKgC8wiOLWc7DN+9pVSzomIWPxz//ESa63vrbVur7VuP8ljARyPWQR0Rat5ZBYBS8wsAn7KyS5+Ph0Rr1/8++sj4lOjaQfghJhFQFeYR0AXmEXAT0kXP6WUj0TE/xcRzyql7CqlvCEi3hERLy+l7IiIly/+G2DJmEVAV5hHQBeYRUBb6Wv81Fpfd5zQfxlxLxxHKSXNufHGGxvj119/fVrj9NNPT3NqrY3xW2+9Na0xPT2d5mzYsCHNeeihhxrjmzZtSmsMBoM0h27o6yzKrqk1a/InZo7i83hhYWHoGhH5+9Nmni1HHxHtemmTk527NjX27NmT5uzcuTPNyYyP5y/tNz8/P/Rx+q6v86hP7rzzzsb4lVdemdZoM0cyd999d5ozimt7VG6//faVboETYBYdW5vH3ez6bnNvtZq+jnj3u9+d5lx00UVpzgUXXJDmnHXWWY3xo0ePpjXGxsbSnM985jON8fPPPz+tsXnz5jRn69atjfG77rorrTEzM5PmLLWT/VEvAAAAADrO4gcAAACgpyx+AAAAAHrK4gcAAACgpyx+AAAAAHrK4gcAAACgpyx+AAAAAHrK4gcAAACgp8ZXugFyDz30UJrzile8ojF+0UUXpTVuu+22NGd6ejrNyWzdujXNWbt2bZqze/fuxvjCwkJao9aa5sCp4PDhw2nOmjX59wrm5+cb46WU1j11wShmxNjYWJqTnbeIiHvvvXfoXuBU8aMf/WjoGm2u3VHYs2fPSOqMYr7u2LFjBJ2wGg37+TOqe+o29xqZwWAwdI3NmzenOS972cvSnBe/+MWN8RtvvDGt0ebcHj16tDH+D//wD2mNm266Kc0ZhXe84x1pzr59+9Kca6+9dhTtDO1d73pXmvOGN7whzfnGN74xinaOyzN+AAAAAHrK4gcAAACgpyx+AAAAAHrK4gcAAACgpyx+AAAAAHrK4gcAAACgpyx+AAAAAHrK4gcAAACgp8ZXugFyU1NTac7evXsb469+9avTGrt27UpzbrnlljQn89WvfjXN2bZtW5rzq7/6q0PX+LM/+7M0B1ZSrXVZjnPkyJE0Z3w8f8jI6qxZs7q+3zAYDNKc7H0qpaQ12uS0+RgBj9m5c+fQNZZrXj344IMjqTMxMTF0jcOHD4+gE1aj7H6jzePUcmjzuNzGFVdc0RifnJxMa7SZM3fddVdjfPfu3WmNCy+8MM255557GuPT09NpjeWysLCQ5jznOc9Zhk7afV5n10ab++OZmZk05+d+7ufSnGGsrjtwAAAAAFqz+AEAAADoKYsfAAAAgJ6y+AEAAADoKYsfAAAAgJ6y+AEAAADoKYsfAAAAgJ7Kf+k8K27jxo1pzt69exvj11xzTVpj3759ac6mTZvSnMxNN92U5lx77bVpzvbt2xvjO3bsaN0TnOrm5+fTnMnJyTRnYWGhMb5mTf79hlprmjMKozpOVqfNuQVG6957722Mz87OpjUmJiZG1E2zUc2i8fHm2/qpqamRHIdT03I9NpdShq7x0pe+NM2ZmZlpjN9www1D9zEqd9xxx9A1xsbG0pzBYJDmtPn4ZHWy+RwR8axnPSvNGYVRfF63+fr40KFDaU42w4flGT8AAAAAPWXxAwAAANBTFj8AAAAAPWXxAwAAANBTFj8AAAAAPWXxAwAAANBTFj8AAAAAPWXxAwAAANBT4yvdALnDhw+nOfPz843x/fv3pzWOHDmS5qxbty7NySwsLKQ5H/zgB9Ocd77znY3xLVu2pDUmJibSnLm5uTQHlkopJc2ptQ59nA0bNqQ5bWbEmjX9+n5Cm/OfGcXHBzgxO3fubIy3uRdpc48wCm16aWN8vPm2/qtf/epIjkM/ZY932WPZKB4vI0ZzPWzdujXNueqqqxrjP/zhD9Ma+/btS3PWrl3bGM++houIGAwGaU728RnVnBnVxznTpXunTZs2Ncaf9KQnpTVmZ2fTnOzzNpvxEc2fT+kdeinlg6WU/aWUOx73tr8opdxfSvmPxf9+Ne0CYAhmEdAV5hHQBWYR0Fabb81+KCJedYy3X1trff7if58dbVsAP+VDYRYB3fChMI+AlfehMIuAFtLFT631xog4sAy9AByXWQR0hXkEdIFZBLQ1zIsxvKWU8u3FpxiefrykUsrVpZTbSim3DXEsgOMxi4CuSOeRWQQsA7MI+Aknu/h5T0Q8PSKeHxF7IuKa4yXWWt9ba91ea91+kscCOB6zCOiKVvPILAKWmFkE/JSTWvzUWvfVWhdqrYOIeF9EvGC0bQHkzCKgK8wjoAvMIuBYTmrxU0o553H//M2IuON4uQBLxSwCusI8ArrALAKOJf1l8KWUj0TEyyLizFLKroj484h4WSnl+RFRI+LeiPidJewRwCwCOsM8ArrALALaShc/tdbXHePNH1iCXhjCpk2bGuOXXXZZWuOGG25IczZs2NC6p+PZunVrmvO0pz0tzVmzpvkJa1u2bElrHDp0KM2hG8yipbV27do0Z2pqKs3JrsvVZjAYpDnj480PpfPz82mN9evXpzlPecpTGuO7d+9Oa/Tt47NSzKPum5mZaYwfPXo0rdFmLi4sLLTuaZgatdY0p5TSGP/e977XuidWh1HOouzzJ3v8aPN5nD1eRuSPmb/4i7+Y1mhzvWTHefKTn5zW2LdvX5qT3UeMYoa0kX1822pzbjNt7nnOPffcoY8zKi9/+csb4+edd15ao83HeWJiojF+8cUXpzW+/e1vHzfmDhAAAACgpyx+AAAAAHrK4gcAAACgpyx+AAAAAHrK4gcAAACgpyx+AAAAAHrK4gcAAACgpyx+AAAAAHpqfKUbYDQeffTRxviVV16Z1rjjjjvSnP3797fu6Xj27t2b5mzevDnNOf/88xvj69evT2vMz8+nObCSSinLcpw21+X4eP6QkfVba01rtMlZrvPSRtZvm/enzbl93vOe1xjfvXt3WqNNL3AqWFhYSHPWrMm/P9rmustMTU2lOaOYeV2am6w+ba6ZzLp169Kc7Hp485vfnNb4yle+kuY8/PDDjfGzzz47rfHtb387zcm+1mgzZ9rkZPcRg8EgrdEmZxRfOx06dCjNaXNfNAobN25Mc97ylrc0xtt8zZl9rR6Rv8+XXHJJWqPpc9IzfgAAAAB6yuIHAAAAoKcsfgAAAAB6yuIHAAAAoKcsfgAAAAB6yuIHAAAAoKcsfgAAAAB6qvmXxbNqbNq0qTH+8Y9/PK1RSklzaq2tezqe++67L815ylOekuZcfvnljfHPf/7zaY2xsbE0Z2FhIc2BrnvRi17UGM9mSETEzMxMmpPNkVHMkOXUZi4OBoNlOc4rX/nKxvjnPve5tMb8/HzrnqDP2jz+t3HzzTcPXeNb3/pWmnPw4ME0Z8uWLY3xNvdWnLqyx7LsmmnzWDg1NXVCPR3Lz/zMz6Q5H/jAB9Kc6667rjF+1VVXpTXafK2R3fe0uS9qc25X0+P7jh070pzl+vrrT/7kT9Kcpz3taY3xNh+f0047Lc05cuRIY7zN19BNPOMHAAAAoKcsfgAAAAB6yuIHAAAAoKcsfgAAAAB6yuIHAAAAoKcsfgAAAAB6yuIHAAAAoKcsfgAAAAB6anylG2A05ufnh4pHRFxwwQVpzv79+9u2dFyHDh1Kc3bs2JHmXHjhhUPFIyL27NmT5sBKGgwGI6nza7/2a43xiYmJtMbU1FSak9UppaQ1aq1pTqbNcdpoc/7Hx5sfStvUWFhYSHNe9apXNcb/4A/+IK3R5txm524UHx9Yatksyq7bttpcu5m5ubk05+jRo0Mf57zzzhu6Bv20du3aOP/88xtzfuu3fqsx3uZzdHZ2Ns3Jvga4+eab0xpPf/rT05y9e/c2xl/ykpekNS699NI059xzz22Mr1mTPw9jy5Ytac5pp53WGG9zXzQ5OZnmrF+/Ps05ePBgY7zNeXv00UfTnDe96U2N8TZf27785S9Pc37wgx80xtvc561bty7N2bVrV2P8pptuSms08YwfAAAAgJ6y+AEAAADoKYsfAAAAgJ6y+AEAAADoKYsfAAAAgJ6y+AEAAADoKYsfAAAAgJ6y+AEAAADoqfEsoZTy1Ij4x4g4OyIGEfHeWuvflFLOiIiPRcQFEXFvRFxVa3146VqlyaZNm4aKR0QcPHgwzXnkkUda97TUvUxPTzfGL7300rTGzTffnObQDX2dRaWUxnitdSTHee1rX9sYn5ubS2usWZN/r2AwGDTGR/X+jKpOJvv4ROS9tDlvR48eHUkvo7Bcn5OrVV9nUd9MTk42xsfGxkZynAsvvHAkdTLZ+xMRsbCw0Bg/44wzRtUOHTDKWXT06NH43ve+13i897///Y3xzZs3pz2fddZZac62bdsa41/5ylfSGldccUWa861vfasx3uZrnl/+5V9Oc7LH9zazaH5+Ps3Jrv+ZmZm0xgMPPJDmHD58OM3Jvka7/vrr0xpt7ote/epXN8b37t2b1rjmmmvSnNnZ2cZ4m4/hkSNH0pz169enOcNo84yf+Yj4X7XW50TEiyLizaWUiyPibRHxpVrrMyLiS4v/BlgqZhHQBWYR0AVmEdBauvipte6ptX5z8e+HIuI7EXFuRFwZEdctpl0XEa9ZqiYBzCKgC8wioAvMIuBEnNBr/JRSLoiIyyLiloh4cq11T8Rjgycimp+XBzAiZhHQBWYR0AVmEZBJX+Pnx0opmyLiExHx+7XWR9u+1kAp5eqIuPrk2gP4SWYR0AVmEdAFZhHQRqtn/JRSJuKxgfJPtdZPLr55XynlnMX4ORGx/1j/b631vbXW7bXW7aNoGDh1mUVAF5hFQBeYRUBb6eKnPLY2/kBEfKfW+tePC306Il6/+PfXR8SnRt8ewGPMIqALzCKgC8wi4ES0+VGvX4qI/x4Rt5dS/mPxbX8cEe+IiP9TSnlDRPwoIv7r0rQIEBFmEdANZhHQBWYR0Fq6+Km13hQRx/th0f8y2nY4WbXWxvjCwkJaY3p6elTtNGrzs8dPfvKT05wdO3Y0xu+///7WPdF9fZ1Fa9Y0P/GyzbXbRjYj5ubmluU4bbSZEdlxRtFHW9mxso9xRMT8/Hyac/rppzfGL7744rTGXXfdleaMjzffGszOzqY1+qyvs6hvDh8+3Bhv83m8fv36NCe7LttoM/MmJyfTnGwWjY2Nte6J7lvuWfTggw8OFY+IuOeee0bVDsR73vOelW5hVTmh3+oFAAAAwOph8QMAAADQUxY/AAAAAD1l8QMAAADQUxY/AAAAAD1l8QMAAADQUxY/AAAAAD1l8QMAAADQU+Mr3QCjcejQocb45s2b0xoLCwtpzqZNm1r3dDxzc3Npzvz8fJqzbt26oXuBlTY2NtYYb3NdPvWpT01ztm7d2hifnZ1Na2S9RkQMBoPGeCklrdHGqOosh1rrSHLWrl3bGL/kkkvSGnfddVea0+ZzDla7PXv2pDlbtmxJc9rcr2TaXP+juC/avXt3654A6BfP+AEAAADoKYsfAAAAgJ6y+AEAAADoKYsfAAAAgJ6y+AEAAADoKYsfAAAAgJ6y+AEAAADoKYsfAAAAgJ4aX+kGGI3Z2dnG+NjYWFpjfn4+zZmenm7d0/HMzc2lOVNTU2nOunXrGuMPP/xw655gpaxZM/z+/aKLLkpzNmzY0BjPZkhEuzkyGAzSnFEopSzLcdqotTbGFxYWlqWPyy67LM35+Mc/nuYs18cQVtJ3v/vdNOfZz352mnP33XePop3Ugw8+mOZs3ry5Mf61r31tVO0AsMp4xg8AAABAT1n8AAAAAPSUxQ8AAABAT1n8AAAAALXM9VMAAAp2SURBVPSUxQ8AAABAT1n8AAAAAPSUxQ8AAABAT42vdAOMxt69exvjmzZtSmusWZPvATds2NC6p2GOMzs7m+ZMTEw0xg8ePNi6J1gppZSha6xbt27o4wwGg7TGwsJCmjM2NtYYr7WmNUahzXlt00ub85IZH88fatuc2/n5+cb4tm3bWvfUJDt3y/UxhONpcx+RXbtf+9rX0hqvec1r0pz9+/enOaNw4MCBNOfCCy9sjN95552jageAVcYzfgAAAAB6yuIHAAAAoKcsfgAAAAB6yuIHAAAAoKcsfgAAAAB6yuIHAAAAoKcsfgAAAAB6yuIHAAAAoKfGs4RSylMj4h8j4uyIGETEe2utf1NK+YuI+J8R8cBi6h/XWj+7VI3S7L777muMP/OZz0xrrFmT7wE3bdrUuqfjOXz4cJpTSklzZmZmGuNzc3Ote6L7+jqLaq1D1zjjjDPSnPn5+cb4wsJCWqPNdZnVGRsbS2u0OSejOG+jkr3PExMTQ9eIiBgMBo3xjRs3pjXaGB9vvjWYnZ0dyXFWq77OotWkzSzKfOITn0hz3vGOd6Q569evH7qXNqampoauccstt4ygE7rCLAJORLr4iYj5iPhftdZvllJOi4hvlFK+sBi7ttb6v5euPYD/ZBYBXWAWAV1gFgGtpYufWuueiNiz+PdDpZTvRMS5S90YwOOZRUAXmEVAF5hFwIk4odf4KaVcEBGXRcSPnyv6llLKt0spHyylnD7i3gCOySwCusAsArrALAIyrRc/pZRNEfGJiPj9WuujEfGeiHh6RDw/Hts2X3Oc/+/qUsptpZTbRtAvcIozi4AuMIuALjCLgDZaLX5KKRPx2ED5p1rrJyMiaq37aq0LtdZBRLwvIl5wrP+31vreWuv2Wuv2UTUNnJrMIqALzCKgC8wioK108VMe+9UJH4iI79Ra//pxbz/ncWm/GRF3jL49gMeYRUAXmEVAF5hFwIlo81u9fiki/ntE3F5K+Y/Ft/1xRLyulPL8iKgRcW9E/M6SdAjwGLMI6AKzCOgCswhorc1v9bopIsoxQp8dfTsAx2YWAV1gFgFdYBYBJ6LNM35YBcbGxhrjExMTIznO1NTU0DUmJyfTnA0bNqQ5g8GgMX748OHWPcFKqbUOXWPbtm1pzubNmxvj8/PzaY2zzjorzcnen9nZ2bTGwsJCmpPNvDbazMU1a/KXwnvs2fYnH4+IeOCBB9KcrN+1a9emNdpoc/5htfv+97+f5rS5FrZvX56XR8nuedq47Tav4QtwqjqhX+cOAAAAwOph8QMAAADQUxY/AAAAAD1l8QMAAADQUxY/AAAAAD1l8QMAAADQUxY/AAAAAD01vtINMBq33357Y/ylL31pWmNmZibNufvuu1v3dDz79u1Lc2655ZY0Z/369Y3xRx55pHVPsFLm5uaGrnHttdemOV//+tcb4xdeeGFa45xzzklzzjvvvMb4aaedltaYnJxMc8bGxhrjR44cSWtMT0+nOUePHk1zDhw40BjftWtXWuP+++9Pc+66667G+M6dO9MabQwGg5HUgaWyXJ+jn/rUp9Kc3bt3L0MnEV/84hfTnIMHDy5DJwCsRp7xAwAAANBTFj8AAAAAPWXxAwAAANBTFj8AAAAAPWXxAwAAANBTFj8AAAAAPWXxAwAAANBTFj8AAAAAPVVqrct3sFIeiIidj3vTmRHx4LI1MLzV1K9el85q6nepej2/1nrWEtRdFmbRstLr0llN/ZpFx3CMWRTh47pUVlOvEaurX72aRStNr0tnNfWr14ZZtKyLn586eCm31Vq3r1gDJ2g19avXpbOa+l1Nva6k1XaeVlO/el06q6nf1dTrSltN50qvS2c19avXflpN50qvS2c19avXZn7UCwAAAKCnLH4AAAAAemqlFz/vXeHjn6jV1K9el85q6nc19bqSVtt5Wk396nXprKZ+V1OvK201nSu9Lp3V1K9e+2k1nSu9Lp3V1K9eG6zoa/wAAAAAsHRW+hk/AAAAACyRFVv8lFJeVUq5u5Ty/VLK21aqjzZKKfeWUm4vpfxHKeW2le7niUopHyyl7C+l3PG4t51RSvlCKWXH4p+nr2SPP3acXv+ilHL/4vn9j1LKr65kjz9WSnlqKeWGUsp3Sil3llL+r8W3d+7cNvTayXPbJWbR6JhFS8MsOjWYRaNjFi2N1TSLIsyjk7WaZlFEt+eRWbQ0zKKT7GMlftSrlDIWEd+LiJdHxK6I+HpEvK7WeteyN9NCKeXeiNhea31wpXs5llLKSyJiKiL+sdZ66eLb/ioiDtRa37E4tE+vtf7RSva52Nexev2LiJiqtf7vleztiUop50TEObXWb5ZSTouIb0TEayLif0THzm1Dr1dFB89tV5hFo2UWLQ2zqP/MotEyi5bGappFEebRyVhtsyii2/PILFoaZtHJWaln/LwgIr5fa72n1jobER+NiCtXqJdVr9Z6Y0QceMKbr4yI6xb/fl089sm14o7TayfVWvfUWr+5+PdDEfGdiDg3OnhuG3qlmVk0QmbR0jCLTglm0QiZRUtjNc2iCPPoJJlFI2QWLQ2z6OSs1OLn3Ii473H/3hXdHsQ1Ij5fSvlGKeXqlW6mpSfXWvdEPPbJFhHbVrifzFtKKd9efJphJ56W93illAsi4rKIuCU6fm6f0GtEx8/tCjOLll6nr5dj6PT1Yhb1llm09Dp9vRxDp6+X1TSLIsyjE7DaZlHE6ptHnb9enqDT14pZ1N5KLX7KMd7W5V8v9ku11p+LiF+JiDcvPhWO0XlPRDw9Ip4fEXsi4pqVbecnlVI2RcQnIuL3a62PrnQ/TY7Ra6fPbQeYRTxep68Xs6jXzCIer9PXy2qaRRHm0QlabbMowjxaSp2+VsyiE7NSi59dEfHUx/37ZyJi9wr1kqq17l78c39E/HM89jTIrtu3+POEP/65wv0r3M9x1Vr31VoXaq2DiHhfdOj8llIm4rEL9J9qrZ9cfHMnz+2xeu3yue0Is2jpdfJ6OZYuXy9mUe+ZRUuvk9fLsXT5ellNsyjCPDoJq2oWRazKedTZ6+WJunytmEUnbqUWP1+PiGeUUp5WSpmMiP8WEZ9eoV4alVI2Lr4IU5RSNkbEKyLijub/qxM+HRGvX/z76yPiUyvYS6MfX6CLfjM6cn5LKSUiPhAR36m1/vXjQp07t8frtavntkPMoqXXuevleLp6vZhFpwSzaOl17no5nq5eL6tpFkWYRydp1cyiiFU7jzp5vRxLV68Vs+gk+6gr8Fu9IiLKY7+u7P+JiLGI+GCt9f9ekUYSpZQL47HtcUTEeER8uGu9llI+EhEvi4gzI2JfRPx5RPxLRPyfiDgvIn4UEf+11rriL9h1nF5fFo89xa1GxL0R8Ts//vnMlVRKuTwivhIRt0fEYPHNfxyP/Uxmp85tQ6+viw6e2y4xi0bHLFoaZtGpwSwaHbNoaaymWRRhHp2s1TKLIro/j8yipWEWnWQfK7X4AQAAAGBprdSPegEAAACwxCx+AAAAAHrK4gcAAACgpyx+AAAAAHrK4gcAAACgpyx+AAAAAHrK4gcAAACgpyx+AAAAAHrq/we/uuCui2sYLwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 1440x360 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(20,5))\n",
    "\n",
    "plt.subplot(141)\n",
    "plt.imshow(X_train[115].reshape(28,28), cmap=\"gray\")\n",
    "\n",
    "plt.subplot(142)\n",
    "plt.imshow(X_train[225].reshape(28,28), cmap=\"gray\")\n",
    "\n",
    "plt.subplot(143)\n",
    "plt.imshow(X_train[330].reshape(28,28), cmap=\"gray\")\n",
    "\n",
    "plt.subplot(144)\n",
    "plt.imshow(X_train[435].reshape(28,28), cmap=\"gray\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.astype('float32') / 255\n",
    "y_train = y_train.astype('float32') / 255\n",
    "X_test = X_test.astype('float32') / 255\n",
    "y_test = y_test.astype('float32') / 255\n",
    "\n",
    "#X_train = to_categorical(X_train)\n",
    "#X_test = to_categorical(X_test)\n",
    "#y_train = to_categorical(y_train)\n",
    "#y_test = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Creation with 5 hidden layers\n",
    "\n",
    "We begin to create a function which will produce the results using 5 hidden layers. This function will allow us to specify specific parameters we can test with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nn_model(First, Second, Third, Fourth, batch_, opt, act):\n",
    "\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(tf.keras.layers.Flatten(input_shape=(28,28)))\n",
    "    model.add(Dense(First, activation=act))\n",
    "    model.add(tf.keras.layers.Dropout(.3))\n",
    "    model.add(Dense(Second, activation=act))\n",
    "    model.add(tf.keras.layers.Dropout(.3))\n",
    "    model.add(Dense(Third, activation=act))\n",
    "    model.add(tf.keras.layers.Dropout(.3))\n",
    "    model.add(Dense(Fourth, activation=act))\n",
    "    model.add(tf.keras.layers.Dropout(.3))\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "    \n",
    "    print(model.summary())\n",
    "    \n",
    "    model.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=opt),\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    model.fit(X_train, y_train, batch_size=batch_, epochs=20, verbose=1, \n",
    "              validation_data=[X_test, y_test])\n",
    "    \n",
    "    score = model.evaluate(X_test, y_test, verbose=0)\n",
    "    print('Test Score:{}'.format(score[0])) #\n",
    "    print('Test Accuracy:{}'.format(score[1])) \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten (Flatten)            (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 575,050\n",
      "Trainable params: 575,050\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 138s 2ms/sample - loss: 0.0074 - acc: 0.0998 - val_loss: 8.5543e-06 - val_acc: 0.1000\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 144s 2ms/sample - loss: 1.6666e-04 - acc: 0.1000 - val_loss: 2.7115e-06 - val_acc: 0.1000\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 145s 2ms/sample - loss: 7.7964e-05 - acc: 0.1000 - val_loss: 1.4571e-06 - val_acc: 0.1000\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 141s 2ms/sample - loss: 6.5716e-05 - acc: 0.1000 - val_loss: 8.8984e-07 - val_acc: 0.1000\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 152s 3ms/sample - loss: 6.2010e-05 - acc: 0.1000 - val_loss: 6.1343e-07 - val_acc: 0.1000\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 154s 3ms/sample - loss: 2.4956e-05 - acc: 0.1000 - val_loss: 4.8709e-07 - val_acc: 0.1000\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 150s 3ms/sample - loss: 3.2650e-05 - acc: 0.1000 - val_loss: 3.8416e-07 - val_acc: 0.1000\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 148s 2ms/sample - loss: 2.2167e-05 - acc: 0.1000 - val_loss: 3.1550e-07 - val_acc: 0.1000\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 156s 3ms/sample - loss: 1.8256e-05 - acc: 0.1000 - val_loss: 2.6542e-07 - val_acc: 0.1000\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 145s 2ms/sample - loss: 2.7242e-05 - acc: 0.1000 - val_loss: 2.1112e-07 - val_acc: 0.1000\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 145s 2ms/sample - loss: 2.4870e-05 - acc: 0.1000 - val_loss: 1.7384e-07 - val_acc: 0.1000\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 144s 2ms/sample - loss: 1.3776e-05 - acc: 0.1000 - val_loss: 1.5264e-07 - val_acc: 0.1000\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 146s 2ms/sample - loss: 1.5473e-05 - acc: 0.1000 - val_loss: 1.3263e-07 - val_acc: 0.1000\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 147s 2ms/sample - loss: 1.7484e-05 - acc: 0.1000 - val_loss: 1.1412e-07 - val_acc: 0.1000\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 144s 2ms/sample - loss: 1.0306e-05 - acc: 0.1000 - val_loss: 1.0341e-07 - val_acc: 0.1000\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 142s 2ms/sample - loss: 1.6243e-05 - acc: 0.1000 - val_loss: 8.9669e-08 - val_acc: 0.1000\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 143s 2ms/sample - loss: 1.4929e-05 - acc: 0.1000 - val_loss: 7.9408e-08 - val_acc: 0.1000\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 143s 2ms/sample - loss: 9.6249e-06 - acc: 0.1000 - val_loss: 7.3162e-08 - val_acc: 0.1000\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 144s 2ms/sample - loss: 9.4405e-06 - acc: 0.1000 - val_loss: 6.6786e-08 - val_acc: 0.1000\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 155s 3ms/sample - loss: 5.6502e-06 - acc: 0.1000 - val_loss: 6.2912e-08 - val_acc: 0.1000\n",
      "Test Score:6.291239713860364e-08\n",
      "Test Accuracy:0.10000000149011612\n"
     ]
    }
   ],
   "source": [
    "nn_model(512, 256, 128, 64, 1, .001, 'relu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_2 (Flatten)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 575,050\n",
      "Trainable params: 575,050\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 28s 463us/sample - loss: 4.7953e-04 - acc: 0.1000 - val_loss: 0.0000e+00 - val_acc: 0.1000\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 25s 424us/sample - loss: 8.4769e-08 - acc: 0.1000 - val_loss: 0.0000e+00 - val_acc: 0.1000\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 25s 423us/sample - loss: 8.7133e-08 - acc: 0.1000 - val_loss: 0.0000e+00 - val_acc: 0.1000\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 25s 420us/sample - loss: 9.0880e-08 - acc: 0.1000 - val_loss: 0.0000e+00 - val_acc: 0.1000\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 25s 421us/sample - loss: 7.5662e-08 - acc: 0.1000 - val_loss: 0.0000e+00 - val_acc: 0.1000\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 25s 419us/sample - loss: 8.7970e-08 - acc: 0.1000 - val_loss: 0.0000e+00 - val_acc: 0.1000\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 25s 417us/sample - loss: 8.4649e-08 - acc: 0.1000 - val_loss: 0.0000e+00 - val_acc: 0.1000\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 25s 421us/sample - loss: 7.7783e-08 - acc: 0.1000 - val_loss: 0.0000e+00 - val_acc: 0.1000\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 26s 426us/sample - loss: 7.0095e-08 - acc: 0.1000 - val_loss: 0.0000e+00 - val_acc: 0.1000\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 25s 421us/sample - loss: 7.5783e-08 - acc: 0.1000 - val_loss: 0.0000e+00 - val_acc: 0.1000\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 25s 418us/sample - loss: 7.7891e-08 - acc: 0.1000 - val_loss: 0.0000e+00 - val_acc: 0.1000\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 25s 418us/sample - loss: 7.8401e-08 - acc: 0.1000 - val_loss: 0.0000e+00 - val_acc: 0.1000\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 25s 413us/sample - loss: 7.5073e-08 - acc: 0.1000 - val_loss: 0.0000e+00 - val_acc: 0.1000\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 25s 416us/sample - loss: 7.4948e-08 - acc: 0.1000 - val_loss: 0.0000e+00 - val_acc: 0.1000\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 25s 411us/sample - loss: 6.9626e-08 - acc: 0.1000 - val_loss: 0.0000e+00 - val_acc: 0.1000\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 25s 412us/sample - loss: 7.3108e-08 - acc: 0.1000 - val_loss: 0.0000e+00 - val_acc: 0.1000\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 25s 415us/sample - loss: 7.7719e-08 - acc: 0.1000 - val_loss: 0.0000e+00 - val_acc: 0.1000\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 26s 426us/sample - loss: 7.1267e-08 - acc: 0.1000 - val_loss: 0.0000e+00 - val_acc: 0.1000\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 26s 435us/sample - loss: 7.2619e-08 - acc: 0.1000 - val_loss: 0.0000e+00 - val_acc: 0.1000\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 25s 413us/sample - loss: 6.1261e-08 - acc: 0.1000 - val_loss: 0.0000e+00 - val_acc: 0.1000\n",
      "Test Score:0.0\n",
      "Test Accuracy:0.10000000149011612\n"
     ]
    }
   ],
   "source": [
    "nn_model(512, 256, 128, 64, 8, 1, 'sigmoid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_3 (Flatten)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 256)               200960    \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 8)                 520       \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 10)                90        \n",
      "=================================================================\n",
      "Total params: 242,722\n",
      "Trainable params: 242,722\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 32s 527us/sample - loss: 2.3212 - acc: 0.1056 - val_loss: 2.2893 - val_acc: 0.2300\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 26s 441us/sample - loss: 2.2947 - acc: 0.1188 - val_loss: 2.2735 - val_acc: 0.2757\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 27s 443us/sample - loss: 2.2652 - acc: 0.1400 - val_loss: 2.2007 - val_acc: 0.2941\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 26s 437us/sample - loss: 2.1399 - acc: 0.1738 - val_loss: 1.9655 - val_acc: 0.2863\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 26s 437us/sample - loss: 1.9461 - acc: 0.1955 - val_loss: 1.7903 - val_acc: 0.2231\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 26s 438us/sample - loss: 1.8315 - acc: 0.2031 - val_loss: 1.7219 - val_acc: 0.2163\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 26s 435us/sample - loss: 1.7790 - acc: 0.2056 - val_loss: 1.6906 - val_acc: 0.2165\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 26s 435us/sample - loss: 1.7477 - acc: 0.2173 - val_loss: 1.6725 - val_acc: 0.2512\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 27s 450us/sample - loss: 1.7246 - acc: 0.2306 - val_loss: 1.6519 - val_acc: 0.2801\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 26s 438us/sample - loss: 1.7035 - acc: 0.2525 - val_loss: 1.6231 - val_acc: 0.3383\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 26s 440us/sample - loss: 1.6773 - acc: 0.2769 - val_loss: 1.5817 - val_acc: 0.3586\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 26s 441us/sample - loss: 1.6414 - acc: 0.3011 - val_loss: 1.5183 - val_acc: 0.4227\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 26s 440us/sample - loss: 1.5988 - acc: 0.3192 - val_loss: 1.4603 - val_acc: 0.4427\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 29s 477us/sample - loss: 1.5608 - acc: 0.3356 - val_loss: 1.4141 - val_acc: 0.4428\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 28s 464us/sample - loss: 1.5336 - acc: 0.3421 - val_loss: 1.3828 - val_acc: 0.4892\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 27s 446us/sample - loss: 1.5067 - acc: 0.3488 - val_loss: 1.3499 - val_acc: 0.4585\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 26s 438us/sample - loss: 1.4880 - acc: 0.3526 - val_loss: 1.3272 - val_acc: 0.4572\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 26s 438us/sample - loss: 1.4679 - acc: 0.3570 - val_loss: 1.3069 - val_acc: 0.4635\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 27s 455us/sample - loss: 1.4552 - acc: 0.3613 - val_loss: 1.2916 - val_acc: 0.4605\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 26s 438us/sample - loss: 1.4395 - acc: 0.3658 - val_loss: 1.2757 - val_acc: 0.4589\n",
      "Test Score:1.2756810167312622\n",
      "Test Accuracy:0.45890000462532043\n"
     ]
    }
   ],
   "source": [
    "nn_model(256, 128, 64, 8, 4, .001, 'sigmoid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_4 (Flatten)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 256)               200960    \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 8)                 520       \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 10)                90        \n",
      "=================================================================\n",
      "Total params: 242,722\n",
      "Trainable params: 242,722\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 29s 486us/sample - loss: 2.3819 - acc: 0.0970 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 26s 437us/sample - loss: 2.3027 - acc: 0.0963 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 26s 439us/sample - loss: 2.3032 - acc: 0.0981 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 27s 443us/sample - loss: 2.3027 - acc: 0.0972 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 26s 438us/sample - loss: 2.3044 - acc: 0.0975 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 26s 438us/sample - loss: 2.3027 - acc: 0.0982 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 26s 440us/sample - loss: 2.3027 - acc: 0.0978 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 27s 443us/sample - loss: 2.3027 - acc: 0.0969 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 30s 494us/sample - loss: 2.3027 - acc: 0.0990 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 29s 478us/sample - loss: 2.3027 - acc: 0.0965 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 26s 431us/sample - loss: 2.3028 - acc: 0.0994 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 26s 426us/sample - loss: 2.3027 - acc: 0.0983 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 27s 453us/sample - loss: 2.3027 - acc: 0.0980 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 26s 425us/sample - loss: 2.3027 - acc: 0.0980 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 26s 436us/sample - loss: 2.3027 - acc: 0.0966 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 27s 446us/sample - loss: 2.3027 - acc: 0.0979 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 32s 537us/sample - loss: 2.3027 - acc: 0.0976 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 38s 630us/sample - loss: 2.3027 - acc: 0.0987 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 31s 515us/sample - loss: 2.3027 - acc: 0.0985 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 27s 456us/sample - loss: 2.3027 - acc: 0.0981 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Test Score:2.3026014873504637\n",
      "Test Accuracy:0.10000000149011612\n"
     ]
    }
   ],
   "source": [
    "nn_model(256, 128, 64, 8, 4, .001, 'relu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Creation with 3 hidden layers\n",
    "\n",
    "Next we begin the creation of a model with 3 hidden laters. A function was also created in order to easily specify certain parameters we want to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nn_model_3(First, Second, Third, batch_, opt, act):\n",
    "\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(tf.keras.layers.Flatten(input_shape=(28,28)))\n",
    "    model.add(Dense(First, activation=act))\n",
    "    model.add(tf.keras.layers.Dropout(.3))\n",
    "    model.add(Dense(Second, activation=act))\n",
    "    model.add(tf.keras.layers.Dropout(.3))\n",
    "    model.add(Dense(Third, activation=act))\n",
    "    model.add(tf.keras.layers.Dropout(.3))\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "    \n",
    "    print(model.summary())\n",
    "    \n",
    "    model.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=opt),\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    model.fit(X_train, y_train, batch_size=batch_, epochs=20, verbose=1, \n",
    "              validation_data=[X_test, y_test])\n",
    "    \n",
    "    score = model.evaluate(X_test, y_test, verbose=0)\n",
    "    print('Test Score:{}'.format(score[0])) #\n",
    "    print('Test Accuracy:{}'.format(score[1])) \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_5 (Flatten)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dropout_17 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dropout_18 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 567,434\n",
      "Trainable params: 567,434\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 32s 525us/sample - loss: 2.1679 - acc: 0.1615 - val_loss: 2.1960 - val_acc: 0.1396\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 26s 430us/sample - loss: 2.2094 - acc: 0.1533 - val_loss: 2.0301 - val_acc: 0.1837\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 25s 410us/sample - loss: 2.2459 - acc: 0.1349 - val_loss: 2.3183 - val_acc: 0.1000\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 24s 401us/sample - loss: 2.3327 - acc: 0.0985 - val_loss: 2.3223 - val_acc: 0.1000\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 24s 398us/sample - loss: 2.3333 - acc: 0.0982 - val_loss: 2.3203 - val_acc: 0.1000\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 24s 398us/sample - loss: 2.3317 - acc: 0.1022 - val_loss: 2.3255 - val_acc: 0.1000\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 24s 399us/sample - loss: 2.3318 - acc: 0.1009 - val_loss: 2.3819 - val_acc: 0.1000\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 24s 396us/sample - loss: 2.3326 - acc: 0.0985 - val_loss: 2.3480 - val_acc: 0.1000\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 24s 397us/sample - loss: 2.3326 - acc: 0.0999 - val_loss: 2.3286 - val_acc: 0.1000\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 24s 395us/sample - loss: 2.3323 - acc: 0.1019 - val_loss: 2.3141 - val_acc: 0.1000\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 24s 396us/sample - loss: 2.3326 - acc: 0.1004 - val_loss: 2.3358 - val_acc: 0.1000\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 24s 400us/sample - loss: 2.3311 - acc: 0.1015 - val_loss: 2.3386 - val_acc: 0.1000\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 24s 399us/sample - loss: 2.3324 - acc: 0.1008 - val_loss: 2.3396 - val_acc: 0.1000\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 24s 396us/sample - loss: 2.3317 - acc: 0.1007 - val_loss: 2.3342 - val_acc: 0.1000\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 24s 401us/sample - loss: 2.3315 - acc: 0.1016 - val_loss: 2.3333 - val_acc: 0.1000\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 25s 418us/sample - loss: 2.3321 - acc: 0.0989 - val_loss: 2.3447 - val_acc: 0.1000\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 25s 409us/sample - loss: 2.3338 - acc: 0.1013 - val_loss: 2.3912 - val_acc: 0.1000\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 24s 403us/sample - loss: 2.3542 - acc: 0.1021 - val_loss: 2.3450 - val_acc: 0.1000\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 24s 397us/sample - loss: 2.3311 - acc: 0.1030 - val_loss: 2.3319 - val_acc: 0.1000\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 24s 398us/sample - loss: 2.3318 - acc: 0.1023 - val_loss: 2.3314 - val_acc: 0.1000\n",
      "Test Score:2.331350387573242\n",
      "Test Accuracy:0.10000000149011612\n"
     ]
    }
   ],
   "source": [
    "nn_model_3(512, 256, 128, 8, 1, 'sigmoid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_6 (Flatten)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 256)               200960    \n",
      "_________________________________________________________________\n",
      "dropout_19 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dropout_20 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dropout_21 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 242,762\n",
      "Trainable params: 242,762\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 28s 461us/sample - loss: 2.1393 - acc: 0.2109 - val_loss: 1.7048 - val_acc: 0.5803\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 26s 428us/sample - loss: 1.5545 - acc: 0.4024 - val_loss: 1.2471 - val_acc: 0.5993\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 25s 421us/sample - loss: 1.2511 - acc: 0.5142 - val_loss: 1.0329 - val_acc: 0.6408\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 25s 423us/sample - loss: 1.0808 - acc: 0.5833 - val_loss: 0.9095 - val_acc: 0.6638\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 25s 422us/sample - loss: 0.9861 - acc: 0.6148 - val_loss: 0.8410 - val_acc: 0.6682\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 26s 427us/sample - loss: 0.9215 - acc: 0.6445 - val_loss: 0.7835 - val_acc: 0.7005\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 26s 429us/sample - loss: 0.8767 - acc: 0.6605 - val_loss: 0.7416 - val_acc: 0.7142\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 26s 426us/sample - loss: 0.8409 - acc: 0.6788 - val_loss: 0.7068 - val_acc: 0.7264\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 25s 422us/sample - loss: 0.8070 - acc: 0.6901 - val_loss: 0.6855 - val_acc: 0.7192\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 25s 424us/sample - loss: 0.7936 - acc: 0.6954 - val_loss: 0.6761 - val_acc: 0.7225\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 25s 424us/sample - loss: 0.7705 - acc: 0.7014 - val_loss: 0.6505 - val_acc: 0.7380\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 25s 420us/sample - loss: 0.7545 - acc: 0.7111 - val_loss: 0.6432 - val_acc: 0.7393\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 26s 426us/sample - loss: 0.7440 - acc: 0.7128 - val_loss: 0.6298 - val_acc: 0.7468\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 26s 428us/sample - loss: 0.7319 - acc: 0.7183 - val_loss: 0.6248 - val_acc: 0.7389\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 27s 454us/sample - loss: 0.7221 - acc: 0.7233 - val_loss: 0.6165 - val_acc: 0.7510\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 28s 467us/sample - loss: 0.7131 - acc: 0.7279 - val_loss: 0.6079 - val_acc: 0.7546\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 28s 462us/sample - loss: 0.7111 - acc: 0.7254 - val_loss: 0.6056 - val_acc: 0.7577\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 26s 433us/sample - loss: 0.7091 - acc: 0.7284 - val_loss: 0.6062 - val_acc: 0.7493\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 29s 485us/sample - loss: 0.7119 - acc: 0.7272 - val_loss: 0.6069 - val_acc: 0.7510\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 30s 500us/sample - loss: 0.7078 - acc: 0.7311 - val_loss: 0.5907 - val_acc: 0.7634\n",
      "Test Score:0.5906656431674957\n",
      "Test Accuracy:0.7634000182151794\n"
     ]
    }
   ],
   "source": [
    "nn_model_3(256, 128, 64, 4, .001, 'sigmoid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_7 (Flatten)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 256)               200960    \n",
      "_________________________________________________________________\n",
      "dropout_22 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_30 (Dense)             (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dropout_23 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_31 (Dense)             (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dropout_24 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_32 (Dense)             (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 242,762\n",
      "Trainable params: 242,762\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 28s 463us/sample - loss: 2.1411 - acc: 0.2052 - val_loss: 1.7187 - val_acc: 0.5951\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 26s 441us/sample - loss: 1.5869 - acc: 0.3953 - val_loss: 1.2751 - val_acc: 0.6214\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 28s 464us/sample - loss: 1.2660 - acc: 0.5179 - val_loss: 1.0512 - val_acc: 0.6557\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 30s 496us/sample - loss: 1.0951 - acc: 0.5851 - val_loss: 0.9144 - val_acc: 0.6742\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 30s 499us/sample - loss: 0.9834 - acc: 0.6274 - val_loss: 0.8234 - val_acc: 0.7054\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 29s 484us/sample - loss: 0.9078 - acc: 0.6579 - val_loss: 0.7647 - val_acc: 0.7057\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 28s 465us/sample - loss: 0.8539 - acc: 0.6771 - val_loss: 0.7142 - val_acc: 0.7274\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 28s 473us/sample - loss: 0.8154 - acc: 0.6895 - val_loss: 0.6847 - val_acc: 0.7314\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 27s 443us/sample - loss: 0.7815 - acc: 0.7047 - val_loss: 0.6622 - val_acc: 0.7414\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 27s 454us/sample - loss: 0.7594 - acc: 0.7109 - val_loss: 0.6390 - val_acc: 0.7504\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 27s 449us/sample - loss: 0.7419 - acc: 0.7166 - val_loss: 0.6295 - val_acc: 0.7583\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 26s 441us/sample - loss: 0.7256 - acc: 0.7247 - val_loss: 0.6123 - val_acc: 0.7700\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 26s 432us/sample - loss: 0.7218 - acc: 0.7265 - val_loss: 0.6155 - val_acc: 0.7643\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 26s 429us/sample - loss: 0.7133 - acc: 0.7313 - val_loss: 0.5995 - val_acc: 0.7713\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 26s 430us/sample - loss: 0.6932 - acc: 0.7416 - val_loss: 0.5887 - val_acc: 0.7741\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 26s 430us/sample - loss: 0.6928 - acc: 0.7395 - val_loss: 0.5892 - val_acc: 0.7783\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 26s 432us/sample - loss: 0.6811 - acc: 0.7451 - val_loss: 0.5815 - val_acc: 0.7800\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 26s 431us/sample - loss: 0.6691 - acc: 0.7545 - val_loss: 0.5702 - val_acc: 0.7941\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 26s 431us/sample - loss: 0.6775 - acc: 0.7501 - val_loss: 0.5760 - val_acc: 0.7879\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 26s 431us/sample - loss: 0.6675 - acc: 0.7578 - val_loss: 0.5712 - val_acc: 0.7921\n",
      "Test Score:0.5711858174324036\n",
      "Test Accuracy:0.7921000123023987\n"
     ]
    }
   ],
   "source": [
    "nn_model_3(256, 128, 64, 4, .001, 'sigmoid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Summary\n",
    "\n",
    "Amongsts the models we tried above, we used 3 and 5 hidden layers with 2 with different batch sizes and optimizers. Initially between 3 and 5 hidden layers, we noticed that more of our models performed better with 3 hidden layers and does not overvit compared to 5 layers.\n",
    "\n",
    "Additionally with an __Accuracy of 79% and a Score of 57%__ our __last model perfomed the best__. This model contains the following parameters.\n",
    "\n",
    "3 hidden layers with 256, 128 and 64 neurons\n",
    "Batch size of  4 \n",
    "learing rate of .001 \n",
    "Optimizer used was 'sigmoid'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
